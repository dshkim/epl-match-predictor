{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV\n",
    "df = pd.read_csv(\"../data/processed/epl_matches_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>result</th>\n",
       "      <th>poss</th>\n",
       "      <th>sh</th>\n",
       "      <th>sot</th>\n",
       "      <th>dist</th>\n",
       "      <th>fk</th>\n",
       "      <th>pk</th>\n",
       "      <th>...</th>\n",
       "      <th>team_Newcastle Utd</th>\n",
       "      <th>team_Norwich City</th>\n",
       "      <th>team_Nottingham Forest</th>\n",
       "      <th>team_Sheffield United</th>\n",
       "      <th>team_Southampton</th>\n",
       "      <th>team_Tottenham</th>\n",
       "      <th>team_Watford</th>\n",
       "      <th>team_West Bromwich Albion</th>\n",
       "      <th>team_West Ham</th>\n",
       "      <th>team_Wolves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date  time  result  poss    sh  sot  dist   fk  pk  ...  \\\n",
       "0           0  2019-08-09    20       1  57.0  15.0  7.0  17.1  1.0   0  ...   \n",
       "1           1  2019-08-17    15       1  63.0  15.0  6.0  18.6  1.0   0  ...   \n",
       "2           2  2019-08-24    17       1  52.0  24.0  4.0  18.8  0.0   1  ...   \n",
       "3           3  2019-08-31    17       1  63.0  15.0  7.0  21.0  0.0   0  ...   \n",
       "4           4  2019-09-14    12       1  74.0  21.0  8.0  13.6  0.0   0  ...   \n",
       "\n",
       "   team_Newcastle Utd  team_Norwich City  team_Nottingham Forest  \\\n",
       "0               False              False                   False   \n",
       "1               False              False                   False   \n",
       "2               False              False                   False   \n",
       "3               False              False                   False   \n",
       "4               False              False                   False   \n",
       "\n",
       "   team_Sheffield United  team_Southampton  team_Tottenham  team_Watford  \\\n",
       "0                  False             False           False         False   \n",
       "1                  False             False           False         False   \n",
       "2                  False             False           False         False   \n",
       "3                  False             False           False         False   \n",
       "4                  False             False           False         False   \n",
       "\n",
       "   team_West Bromwich Albion  team_West Ham  team_Wolves  \n",
       "0                      False          False        False  \n",
       "1                      False          False        False  \n",
       "2                      False          False        False  \n",
       "3                      False          False        False  \n",
       "4                      False          False        False  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by date to ensure chronological order\n",
    "df_sorted = df.sort_values(by='date')\n",
    "\n",
    "# Define a split point; use 80% of the data for training and 20% for testing\n",
    "split_date = df_sorted['date'].quantile(0.8)\n",
    "\n",
    "# Split the data\n",
    "train_df = df_sorted[df_sorted['date'] <= split_date]\n",
    "test_df = df_sorted[df_sorted['date'] > split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'result'\n",
    "feature_columns = df.drop(['date', 'Unnamed: 0', 'result'], axis=1).columns\n",
    "\n",
    "# For training data\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df[target_column]\n",
    "\n",
    "# For testing data\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "Accuracy: 0.5907894736842105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.68      0.65       298\n",
      "           0       0.30      0.05      0.08       164\n",
      "           1       0.59      0.80      0.68       298\n",
      "\n",
      "    accuracy                           0.59       760\n",
      "   macro avg       0.50      0.51      0.47       760\n",
      "weighted avg       0.54      0.59      0.54       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, min_samples_split=10, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Score: 0.5692664527876528\n",
      "Accuracy: 0.6065789473684211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.74      0.67       298\n",
      "           0       0.50      0.01      0.01       164\n",
      "           1       0.60      0.81      0.69       298\n",
      "\n",
      "    accuracy                           0.61       760\n",
      "   macro avg       0.57      0.52      0.46       760\n",
      "weighted avg       0.58      0.61      0.54       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Train with GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model performance\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV\n",
    "df_clean = pd.read_csv(\"../data/interim/epl_matches_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unncessary columns\n",
    "df_clean.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a rolling average function\n",
    "def rolling_averages(group, cols, new_cols):\n",
    "    group = group.sort_values('date')\n",
    "    rolling_stats = group[cols].rolling(2, closed = 'left').mean()\n",
    "    group[new_cols] = rolling_stats\n",
    "    group = group.dropna(subset=new_cols)\n",
    "    return group    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sh\", \"sot\", \"dist\", \"fk\", \"pk\", \"pkatt\"]\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/g4b_94bd7fggx8kn5fnnsdc00000gn/T/ipykernel_63900/3789540631.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  matches_rolling = df_clean.groupby(\"team\").apply(lambda x: rolling_averages(x, cols, new_cols))\n"
     ]
    }
   ],
   "source": [
    "#Apply rolling averages to numerical columns in DataFrame\n",
    "matches_rolling = df_clean.groupby(\"team\").apply(lambda x: rolling_averages(x, cols, new_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_rolling = matches_rolling.droplevel('team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct index\n",
    "matches_rolling.index = range(matches_rolling.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "matches_rolling = pd.get_dummies(matches_rolling, columns=['round', 'day', 'venue', 'opponent', 'formation', 'team'])\n",
    "\n",
    "#Keep only hour for time column\n",
    "matches_rolling['time'] = matches_rolling['time'].str.split(':').str[0].astype('int')\n",
    "\n",
    "# Convert result to numerical outcome: 1 for home win, -1 for away win, 0 for draw\n",
    "matches_rolling['result'] = matches_rolling['result'].map({'W': 1, 'L': -1, 'D': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to clean column names\n",
    "def clean_column_names(columns):\n",
    "    cleaned_columns = []\n",
    "    for col in columns:\n",
    "        # Remove unwanted characters using regex\n",
    "        cleaned_col = re.sub(r'[^\\w\\s]', '', col)  # Removes all non-alphanumeric characters except whitespace\n",
    "        cleaned_columns.append(cleaned_col)\n",
    "    return cleaned_columns\n",
    "\n",
    "# Apply the cleaning function\n",
    "matches_rolling.columns = clean_column_names(matches_rolling.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated columns based on column names\n",
    "matches_rolling = matches_rolling.loc[:, ~matches_rolling.columns.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "rolling_train_df = matches_rolling[matches_rolling['date'] <= '2023-08-01']\n",
    "rolling_test_df = matches_rolling[matches_rolling['date'] > '2023-08-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'result'\n",
    "feature_columns = matches_rolling.drop(['result', 'date'], axis=1).columns\n",
    "\n",
    "# For training data\n",
    "rolling_X_train = rolling_train_df[feature_columns]\n",
    "rolling_y_train = rolling_train_df[target_column]\n",
    "\n",
    "# For testing data\n",
    "rolling_X_test = rolling_test_df[feature_columns]\n",
    "rolling_y_test = rolling_test_df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "Accuracy: 0.5989445910290238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.70      0.66       296\n",
      "           0       0.37      0.04      0.08       164\n",
      "           1       0.59      0.81      0.68       298\n",
      "\n",
      "    accuracy                           0.60       758\n",
      "   macro avg       0.53      0.52      0.47       758\n",
      "weighted avg       0.56      0.60      0.54       758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "rolling_models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, min_samples_split=10, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in rolling_models.items():\n",
    "    model.fit(rolling_X_train, rolling_y_train)\n",
    "    rolling_y_pred = model.predict(rolling_X_test)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(rolling_y_test, rolling_y_pred)}\")\n",
    "    print(classification_report(rolling_y_test, rolling_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Score: 0.5162316599721013\n",
      "Accuracy: 0.5989445910290238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.71      0.67       296\n",
      "           0       0.42      0.03      0.06       164\n",
      "           1       0.58      0.80      0.67       298\n",
      "\n",
      "    accuracy                           0.60       758\n",
      "   macro avg       0.54      0.51      0.47       758\n",
      "weighted avg       0.56      0.60      0.54       758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rolling_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "rolling_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "rolling_grid_search = GridSearchCV(estimator=rolling_model, param_grid=rolling_param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Train with GridSearchCV\n",
    "rolling_grid_search.fit(rolling_X_train, rolling_y_train)\n",
    "\n",
    "# Best parameters and model performance\n",
    "print(f\"Best Parameters: {rolling_grid_search.best_params_}\")\n",
    "print(f\"Best Score: {rolling_grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "rolling_best_model = rolling_grid_search.best_estimator_\n",
    "rolling_y_pred = rolling_best_model.predict(rolling_X_test)\n",
    "print(f\"Accuracy: {accuracy_score(rolling_y_test, rolling_y_pred)}\")\n",
    "print(classification_report(rolling_y_test, rolling_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
